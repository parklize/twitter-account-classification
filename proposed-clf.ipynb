{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# reproducible\n",
    "from numpy.random import seed\n",
    "seed(7)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(77)\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# prepare my data\n",
    "with open(\"data/mydata.pkl\", \"rb\") as f:\n",
    "    mydata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# prepare training data\n",
    "with open(\"data/training_data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# prepare humanizer data\n",
    "with open(\"data/humanizer_data.pkl\", \"rb\") as f:\n",
    "    humanizer_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(model, user_json_str):\n",
    "    \"\"\" \n",
    "    Parameters:\n",
    "    -------------------\n",
    "    model: loaded CV model for extracting image features\n",
    "    user_json_str: User json file\n",
    "    \n",
    "    Return:\n",
    "    -------------------\n",
    "    userid, VGG16 features (25088 dim)\n",
    "    \"\"\"\n",
    "    \n",
    "    # load json\n",
    "    user_json = json.loads(user_json_str)\n",
    "    # get user id\n",
    "    uid = user_json[\"id\"]\n",
    "    # get image url\n",
    "    print(\"retrieving from {} for {}\".format(user_json[\"profile_image_url_https\"], uid))\n",
    "    urllib.request.urlretrieve(user_json[\"profile_image_url_https\"], \"profile.jpg\")\n",
    "    \n",
    "    # get features\n",
    "    image = tf.keras.preprocessing.image.load_img(\"profile.jpg\", target_size=(224,224))\n",
    "    input_arr = keras.preprocessing.image.img_to_array(image)\n",
    "    input_arr = np.array([input_arr])\n",
    "    features = model.predict(input_arr)\n",
    "#     print(features.shape)\n",
    "    features = features.flatten()\n",
    "    \n",
    "    return uid, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_features(user_data):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---------------------\n",
    "    user_data: loaded json for user object\n",
    "    \n",
    "    Return\n",
    "    ---------------------\n",
    "    statistical features\n",
    "    \"\"\"\n",
    "    url_exist = 1 if 'url' in user_data else 0\n",
    "    default_profile = int(user_data['default_profile']) if 'default_profile' in user_data else 1\n",
    "    verified = int(user_data['verified']) if 'verified' in user_data else 0\n",
    "    desc_exist = 1 if 'description' in user_data else 0\n",
    "    default_profile_image = 1 if 'default' in user_data['profile_image_url'] else 0\n",
    "    listed_count = int(user_data['listed_count']) if 'listed_count' in user_data else 0\n",
    "    followers = user_data['followers_count'] if 'followers_count' in user_data else 0\n",
    "    followees = user_data['friends_count'] if 'friends_count' in user_data else 0\n",
    "    posts = user_data['statuses_count'] if 'statuses_count' in user_data else 0\n",
    "    favorites = user_data['favourites_count'] if 'favourites_count' in user_data else 0\n",
    "    len_screenname = len(user_data['screen_name'])\n",
    "    \n",
    "    # engineered (check needed)\n",
    "    ff_ratio = followers / (followees+1.)\n",
    "    fff_ratio = followees / (followees+followers+1.)\n",
    "    \n",
    "    return np.log10(np.array([url_exist, \n",
    "                     default_profile, \n",
    "                     verified, \n",
    "                     desc_exist,\n",
    "                     default_profile_image,\n",
    "                     listed_count,\n",
    "                     followers,\n",
    "                     followees,\n",
    "                     posts,\n",
    "                     favorites,\n",
    "                     len_screenname,\n",
    "                     ff_ratio,\n",
    "                     fff_ratio\n",
    "                    ])+1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ml_img_data(data_pkl, img_features_pkl):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ------------------\n",
    "    data_pkl: path to data pickle\n",
    "    img_features_pkl: path to image feature pickle\n",
    "    \n",
    "    Return\n",
    "    ------------------\n",
    "    X, y for fitting\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # prepare y_train\n",
    "    with open(data_pkl, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    y_train = list()\n",
    "    for uid in data.keys():\n",
    "        y_train.append(data[uid]['label'])\n",
    "\n",
    "    print(len(y_train))\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    # prepare X_train\n",
    "    with open(img_features_pkl, \"rb\") as f:\n",
    "        img_feature_dict = pickle.load(f)\n",
    "    X_train = np.array(list(img_feature_dict.values()))\n",
    "\n",
    "    print(X_train.shape)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "        \n",
    "    print(\"Used {} seconds to load data\".format(elapsed_time))\n",
    "    \n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def get_ml_stat_data(data_pkl=None):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    data = None\n",
    "    if data_pkl is not None:\n",
    "        # prepare y_train\n",
    "        with open(data_pkl, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        X_train = list()\n",
    "        y_train = list()\n",
    "        for uid in data.keys():\n",
    "            y_train.append(data[uid]['label'])\n",
    "            json_data = json.loads(data[uid]['user'].AsJsonString())\n",
    "            X_train.append(get_stat_features(json_data))\n",
    "\n",
    "        y_train = [int(x) for x in y_train]\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        X_train = np.array(X_train)\n",
    "    else:\n",
    "        if os.path.exists(\"data/X_np_training_stat_features.npy\") and os.path.exists(\"data/y_np_training.npy\"):\n",
    "            print(\"Loading training data from existing files...\")\n",
    "            X_train = np.load(\"data/X_np_training_stat_features.npy\")\n",
    "            y_train = np.load(\"data/y_np_training.npy\")\n",
    "        else:\n",
    "            print(\"Nothing to load...\")\n",
    "    \n",
    "    print(X_train.shape, y_train.shape)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "        \n",
    "    print(\"Used {} seconds to load data\".format(elapsed_time))\n",
    "    \n",
    "    return X_train, y_train, data\n",
    "\n",
    "def get_ml_screennames(data_pkl, seq_len=50):\n",
    "    X_mydata_screennames = None\n",
    "    with open(data_pkl, \"rb\") as f:\n",
    "        X_mydata_screennames = pickle.load(f)\n",
    "\n",
    "    # lowercase\n",
    "    X_mydata_screennames = [x.lower() for x in X_mydata_screennames]\n",
    "    \n",
    "    characters_ = [[x for x in y] for y in X_mydata_screennames]\n",
    "    characters = [item for sublist in characters_ for item in sublist]\n",
    "    vocab = list(set(characters))\n",
    "    vocab = sorted(vocab)\n",
    "    print(\"lenth of vocab: {}\".format(len(vocab)))\n",
    "\n",
    "    char2idx = {char:i for i, char in enumerate(vocab)}\n",
    "    idx2char = np.array(vocab)\n",
    "\n",
    "    # encoded screennames\n",
    "    X_mydata_screennames_encoded = [[char2idx[c] for c in n] for n in X_mydata_screennames]\n",
    "\n",
    "    X_mydata_screennames_encoded_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        X_mydata_screennames_encoded, padding=\"pre\", maxlen=seq_len, value=len(vocab))\n",
    "    \n",
    "    return X_mydata_screennames_encoded_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image model\n",
    "def image_classifier():\n",
    "    \"\"\" Use features from VGG16 for binary classification \"\"\"\n",
    "    tf.keras.backend.set_learning_phase(1)\n",
    "    tf.keras.backend.clear_session()\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(1024, input_shape=input_shape, activation=\"relu\"))\n",
    "#     model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    img_inputs = tf.keras.Input(shape=(25088,), dtype=\"float32\")\n",
    "    img_x_ = tf.keras.layers.Dense(1024, activation=\"relu\")(img_inputs)\n",
    "    img_x_ = tf.keras.layers.Dense(256, activation=\"relu\")(img_x_)\n",
    "      \n",
    "    # output\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(img_x_)\n",
    "    model = tf.keras.Model(img_inputs, outputs)\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# screen name model\n",
    "def screenname_classifier():\n",
    "    tf.keras.backend.set_learning_phase(1)\n",
    "    tf.keras.backend.clear_session()\n",
    "    inputs = tf.keras.Input(shape=(None,), dtype=\"int8\")\n",
    "    x = tf.keras.layers.Embedding(input_dim=50, output_dim=100)(inputs)\n",
    "    x = tf.keras.layers.Bidirectional(GRU(128))(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# stat model\n",
    "def mlp_classifier():\n",
    "    tf.keras.backend.set_learning_phase(1)\n",
    "    tf.keras.backend.clear_session()\n",
    "    inputs = tf.keras.Input(shape=(13,), dtype=\"float32\")\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(inputs)\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "def sn_stat_classifier():\n",
    "    tf.keras.backend.set_learning_phase(1)\n",
    "    tf.keras.backend.clear_session()\n",
    "    stat_inputs = tf.keras.Input(shape=(13,), dtype=\"float32\")\n",
    "    stat_x = tf.keras.layers.Dense(128, activation=\"relu\")(stat_inputs)\n",
    "    \n",
    "    sn_inputs = tf.keras.Input(shape=(None,), dtype=\"int8\")\n",
    "    sn_x = tf.keras.layers.Embedding(input_dim=50, output_dim=100)(sn_inputs)\n",
    "    sn_x = tf.keras.layers.Bidirectional(GRU(128))(sn_x)\n",
    "    sn_x = tf.keras.layers.Dense(128, activation=\"relu\")(sn_x)\n",
    "    \n",
    "    # concat\n",
    "    x = tf.keras.layers.concatenate([sn_x, stat_x], axis=1)\n",
    "    \n",
    "    # output\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model([stat_inputs, sn_inputs], outputs)\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "def img_sn_stat_classifier():\n",
    "    tf.keras.backend.set_learning_phase(1)\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    stat_inputs = tf.keras.Input(shape=(13,), dtype=\"float32\")\n",
    "    stat_x = tf.keras.layers.Dense(128, activation=\"relu\")(stat_inputs)\n",
    "    \n",
    "    sn_inputs = tf.keras.Input(shape=(None,), dtype=\"int8\")\n",
    "    sn_x = tf.keras.layers.Embedding(input_dim=50, output_dim=100)(sn_inputs)\n",
    "    sn_x = tf.keras.layers.Bidirectional(GRU(128))(sn_x)\n",
    "    sn_x = tf.keras.layers.Dense(128, activation=\"relu\")(sn_x)\n",
    "    \n",
    "#     # concat\n",
    "    non_img_x_ = tf.keras.layers.concatenate([sn_x, stat_x], axis=1)\n",
    "    \n",
    "    # image part\n",
    "    img_inputs = tf.keras.Input(shape=(25088,), dtype=\"float32\")\n",
    "    img_x_ = tf.keras.layers.Dense(1024, activation=\"relu\")(img_inputs)\n",
    "    img_x_ = tf.keras.layers.Dense(256, activation=\"relu\")(img_x_)\n",
    "    \n",
    "    # manual attention part\n",
    "    img_inputs_sum = tf.math.reduce_sum(img_inputs, axis=1, keepdims=True)\n",
    "    print(\"img_inputs_sum\", img_inputs_sum.shape)\n",
    "    img_inputs_retrived = tf.math.greater(img_inputs_sum, tf.constant([0.]))\n",
    "    img_inputs_retrived = tf.cast(img_inputs_retrived, tf.float32)\n",
    "    print(\"img_inputs_retrived\", img_inputs_retrived.shape)\n",
    "    \n",
    "    alpha = tf.math.multiply(tf.reshape(np.log10(2.)-stat_inputs[:, 4], [-1,1]), img_inputs_retrived)\n",
    "    img_x = tf.math.multiply(alpha, img_x_)\n",
    "    non_img_x = tf.math.multiply(tf.reshape(np.log10(2.)-alpha, [-1,1]), non_img_x_)\n",
    "    fused_x = tf.math.add(img_x, non_img_x)\n",
    "    \n",
    "    # output\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(fused_x)\n",
    "    model = tf.keras.Model([stat_inputs, sn_inputs, img_inputs], outputs)\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and Store Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#############################\n",
    "# get image features\n",
    "\n",
    "data = humanizer_data\n",
    "\n",
    "# load VGG16\n",
    "model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000\n",
    ")\n",
    "\n",
    "# feature dict\n",
    "img_feature_dict = dict()\n",
    "feature_shape = 25088\n",
    "for idx, uid in enumerate(data.keys()):\n",
    "    if idx % 100 == 0:\n",
    "        print(idx, uid)\n",
    "    try:\n",
    "        uid, features = get_image_features(model, data[uid]['user'].AsJsonString())\n",
    "#         print(features.shape)\n",
    "        img_feature_dict[uid] = features\n",
    "    except Exception as e:\n",
    "        print(uid, e)\n",
    "        img_feature_dict[uid] = [0]*feature_shape\n",
    "\n",
    "\n",
    "X_train = np.array(list(img_feature_dict.values()))\n",
    "np.save(\"data/X_np_humanizer_image_features\", X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and Store Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# store statistical features\n",
    "start_time = time.time()\n",
    "\n",
    "X_train = list()\n",
    "y_train = list()\n",
    "for uid in data.keys():\n",
    "    y_train.append(data[uid]['label'])\n",
    "    json_data = json.loads(data[uid]['user'].AsJsonString())\n",
    "    X_train.append(get_stat_features(json_data))\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"Used {} seconds to load data\".format(elapsed_time))\n",
    "\n",
    "np.save(\"data/X_np_humanizer_stat_features\", X_train)\n",
    "np.save(\"data/y_np_humanizer\", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and Store Twitter Screennames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get all screennames\n",
    "screennames = list()\n",
    "for uid in data.keys():\n",
    "    json_data = json.loads(data[uid]['user'].AsJsonString())\n",
    "    screennames.append(json_data[\"screen_name\"])\n",
    "    \n",
    "with open(\"data/humanizer_screennames.pkl\", \"wb\") as f:\n",
    "    pickle.dump(screennames, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train my proposed architecture\n",
    "\n",
    "# load data\n",
    "X_train_img = np.load(\"data/X_np_training_image_features.npy\")\n",
    "X_train_screennames = get_ml_screennames(\"data/training_data_screennames.pkl\")\n",
    "X_train_stat, y_train = get_ml_stat_data()\n",
    "\n",
    "print(X_train_screennames.shape, X_train_stat.shape, X_train_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get val\n",
    "X_train_stat_, X_val_stat_, y_train_stat_, y_val_stat_ = train_test_split(\n",
    "    X_train_stat, y_train, test_size=0.33, random_state=42, stratify=y_train)\n",
    "\n",
    "X_train_sn_, X_val_sn_, y_train_sn_, y_val_sn_ = train_test_split(\n",
    "    X_train_screennames, y_train, test_size=0.33, random_state=42, stratify=y_train)\n",
    "\n",
    "X_train_img_, X_val_img_, y_train_img_, y_val_img_ = train_test_split(\n",
    "    X_train_img, y_train, test_size=0.33, random_state=42, stratify=y_train)\n",
    "\n",
    "print(\"Validation split finished...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and eval - Image Classifier\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# train img classifier\n",
    "# X_train_, X_val, y_train_, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.33, random_state=42, stratify=y_train)\n",
    "\n",
    "# print(\"Split completed...\")\n",
    "\n",
    "# input_shape = X_train.shape[1:]\n",
    "model = image_classifier()\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "# early stopping\n",
    "es = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, \n",
    "                   patience=10,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train_img_, y_train_stat_, \n",
    "          validation_data=(X_val_img_, y_val_stat_), \n",
    "          epochs=500, \n",
    "          batch_size=1024,\n",
    "          verbose=1, \n",
    "          callbacks=[es])\n",
    "\n",
    "# store the model\n",
    "model.save_weights(\"./model/img_clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# evaluate on mydata\n",
    "X_test_mydata = np.load(\"data/X_np_mydata_image_features.npy\")\n",
    "y_test_mydata = np.load(\"data/y_np_mydata.npy\")\n",
    "\n",
    "model = image_classifier()\n",
    "model.load_weights(\"./model/img_clf\")\n",
    "\n",
    "pred = model.predict(X_test_mydata)\n",
    "pred = np.array(pred>=.5).astype(int)\n",
    "y_test_mydata = np.array([int(x) for x in y_test_mydata])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_mydata, \n",
    "                            pred,\n",
    "                            labels = [1,0],\n",
    "                            target_names=[\"ind\",\"org\"]))\n",
    "\n",
    "with open(\"output/mydata_img_classifier.tsv\", \"w\") as f:\n",
    "    for idx, uid in enumerate(mydata.keys()):\n",
    "        f.write(\"{}\\t{}\\n\".format(uid, pred[idx][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# evaluate on humanizer data\n",
    "X_test_humanizer = np.load(\"data/X_np_humanizer_image_features.npy\")\n",
    "y_test_humanizer = np.load(\"data/y_np_humanizer.npy\")\n",
    "\n",
    "model = image_classifier()\n",
    "model.load_weights(\"./model/img_01/img_clf\")\n",
    "\n",
    "pred = model.predict(X_test_humanizer)\n",
    "pred = np.array(pred>=.5).astype(int)\n",
    "y_test_humanizer = np.array([int(x) for x in y_test_humanizer])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_humanizer, \n",
    "                            pred,\n",
    "                            labels = [1,0],\n",
    "                            target_names=[\"ind\",\"org\"]))\n",
    "\n",
    "with open(\"output/humanizer_img_classifier.tsv\", \"w\") as f:\n",
    "    for idx, uid in enumerate(data.keys()):\n",
    "        f.write(\"{}\\t{}\\n\".format(uid, pred[idx][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and eval - Screenname-based Classifier\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#######################################\n",
    "# GRU screenname based classifier\n",
    "model = screenname_classifier()\n",
    "\n",
    "# compile\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=.01)\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "# early stopping\n",
    "es = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, \n",
    "                   patience=10,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# # get val\n",
    "# X_train_, X_val, y_train_, y_val = train_test_split(\n",
    "#     screennames_encoded_padded, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train_sn_, y_train_sn_, \n",
    "          validation_data=(X_val_sn_, y_val_sn_), \n",
    "          epochs=500, \n",
    "          batch_size=1024,\n",
    "          verbose=1, \n",
    "          callbacks=[es])\n",
    "\n",
    "# store the model\n",
    "model.save_weights(\"./model/screenname_clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test with my data\n",
    "model = screenname_classifier()\n",
    "model.load_weights(\"./model/screenname_clf\")\n",
    "\n",
    "X_mydata_screennames_encoded_padded = get_ml_screennames(\"data/mydata_screennames.pkl\") \n",
    "y_mydata = np.load(\"data/y_np_mydata.npy\")\n",
    "\n",
    "print(len(X_mydata_screennames_encoded_padded), len(y_mydata))\n",
    "\n",
    "pred = model.predict(X_mydata_screennames_encoded_padded)\n",
    "pred = np.array(pred>=.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_mydata, \n",
    "                            pred,\n",
    "                            labels = [1, 0],\n",
    "                            target_names=[\"ind\",\"org\"]))\n",
    "\n",
    "with open(\"output/mydata_screenname_classifier.tsv\", \"w\") as f:\n",
    "    for idx, uid in enumerate(mydata.keys()):\n",
    "        f.write(\"{}\\t{}\\n\".format(uid, pred[idx][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test with humanizer data\n",
    "X_humanizer_screennames_encoded_padded = get_ml_screennames(\"data/humanizer_screennames.pkl\") \n",
    "y_humanizer = np.load(\"data/y_np_humanizer.npy\")\n",
    "\n",
    "print(len(X_humanizer_screennames_encoded_padded), len(y_humanizer))\n",
    "\n",
    "model = screenname_classifier()\n",
    "model.load_weights(\"model/screenname_clf\")\n",
    "\n",
    "pred = model.predict(X_humanizer_screennames_encoded_padded)\n",
    "pred = np.array(pred>=.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_humanizer, \n",
    "                            pred,\n",
    "                            labels = [1, 0],\n",
    "                            target_names=[\"ind\",\"org\"]))\n",
    "\n",
    "with open(\"output/humanizer_screenname_classifier.tsv\", \"w\") as f:\n",
    "    for idx, uid in enumerate(data.keys()):\n",
    "        f.write(\"{}\\t{}\\n\".format(uid, pred[idx][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and eval - MLP with Statistical Features Classifier\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "##################################\n",
    "# mlp classifier\n",
    "model = mlp_classifier()\n",
    "\n",
    "# compile\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=.01)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "# early stopping\n",
    "es = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, \n",
    "                   patience=10,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# get val\n",
    "# X_train_, X_val, y_train_, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train_stat_, y_train_stat_, \n",
    "          validation_data=(X_val_stat_, y_val_stat_), \n",
    "          epochs=500, \n",
    "          batch_size=1024,\n",
    "          verbose=1, \n",
    "          callbacks=[es])\n",
    "\n",
    "# store the model\n",
    "model.save_weights(\"./model/mlp_clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test with my data\n",
    "model = mlp_classifier()\n",
    "model.load_weights(\"./model/mlp_clf\")\n",
    "\n",
    "X_mydata_stat, y_mydata_stat, mydata = get_ml_stat_data(\"data/mydata.pkl\")\n",
    "pred = model.predict(X_mydata_stat)\n",
    "pred = np.array(pred>=.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_mydata_stat, \n",
    "                            pred,\n",
    "                            labels = [1, 0],\n",
    "                            target_names=[\"ind\",\"org\"]))\n",
    "\n",
    "with open(\"output/mydata_stat_classifier.tsv\", \"w\") as f:\n",
    "    for idx, uid in enumerate(mydata.keys()):\n",
    "        f.write(\"{}\\t{}\\n\".format(uid, pred[idx][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test with humanizer data\n",
    "model = mlp_classifier()\n",
    "model.load_weights(\"./model/mlp_clf\")\n",
    "\n",
    "# X_mydata_stat, y_mydata_stat, mydata = get_ml_stat_data(\"data/mydata.pkl\")\n",
    "X_humanizer_stat = np.load(\"data/X_np_humanizer_stat_features.npy\")\n",
    "y_humanizer_stat = np.load(\"data/y_np_humanizer.npy\")\n",
    "\n",
    "pred = model.predict(X_humanizer_stat)\n",
    "pred = np.array(pred>=.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_humanizer_stat, \n",
    "                            pred,\n",
    "                            labels = [1, 0],\n",
    "                            target_names=[\"ind\",\"org\"]))\n",
    "\n",
    "with open(\"output/humanizer_stat_classifier.tsv\", \"w\") as f:\n",
    "    for idx, uid in enumerate(data.keys()):\n",
    "        f.write(\"{}\\t{}\\n\".format(uid, pred[idx][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and eval - Statistical Features & Screennames Classifier\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "########################\n",
    "# stat & screennames\n",
    "\n",
    "model = sn_stat_classifier()\n",
    "# compile\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=.01)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "# early stopping\n",
    "es = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, \n",
    "                   patience=10,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# # get val\n",
    "# X_train_stat, X_val_stat, y_train_stat, y_val_stat = train_test_split(\n",
    "#     X_train, y_train, test_size=0.2, random_state=42)\n",
    "# # get val\n",
    "# X_train_sn, X_val_sn, y_train_sn, y_val_sn = train_test_split(\n",
    "#     screennames_encoded_padded, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# fit\n",
    "model.fit([X_train_stat_, X_train_sn_], y_train_stat_, \n",
    "          validation_data=([X_val_stat_, X_val_sn_], y_val_stat_), \n",
    "          epochs=500, \n",
    "          batch_size=1024,\n",
    "          verbose=1, \n",
    "          callbacks=[es])\n",
    "\n",
    "# store the model\n",
    "model.save_weights(\"./model/stat_sn_clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test with mydata\n",
    "X_mydata_screennames = get_ml_screennames(\"data/mydata_screennames.pkl\")\n",
    "X_mydata_stat, y_mydata_stat, mydata = get_ml_stat_data(\"data/mydata.pkl\")\n",
    "\n",
    "# load model\n",
    "model = sn_stat_classifier()\n",
    "model.load_weights(\"./model/stat_sn_clf\")\n",
    "\n",
    "pred = model.predict([X_mydata_stat, X_mydata_screennames_encoded_padded])\n",
    "pred = np.array(pred>=.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_mydata_stat, \n",
    "                            pred,\n",
    "                            labels = [1, 0],\n",
    "                            target_names=[\"ind\",\"org\"]))\n",
    "\n",
    "with open(\"output/mydata_stat_sn_classifier.tsv\", \"w\") as f:\n",
    "    for idx, uid in enumerate(mydata.keys()):\n",
    "        f.write(\"{}\\t{}\\n\".format(uid, pred[idx][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test with humanizer data\n",
    "X_humanizer_screennames = get_ml_screennames(\"data/humanizer_screennames.pkl\")\n",
    "X_humanizer_stat = np.load(\"data/X_np_humanizer_stat_features.npy\")\n",
    "y_humanizer_stat = np.load(\"data/y_np_humanizer.npy\")\n",
    "\n",
    "# load model\n",
    "model = sn_stat_classifier()\n",
    "model.load_weights(\"./model/stat_sn_clf\")\n",
    "\n",
    "pred = model.predict([X_humanizer_stat, X_humanizer_screennames])\n",
    "pred = np.array(pred>=.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_humanizer_stat, \n",
    "                            pred,\n",
    "                            labels = [1, 0],\n",
    "                            target_names=[\"ind\",\"org\"]))\n",
    "\n",
    "with open(\"output/humanizer_stat_sn_classifier.tsv\", \"w\") as f:\n",
    "    for idx, uid in enumerate(data.keys()):\n",
    "        f.write(\"{}\\t{}\\n\".format(uid, pred[idx][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and eval - Proposed Classifier\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#############################\n",
    "# proposed model\n",
    "model = img_sn_stat_classifier()\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "# early stopping\n",
    "es = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, \n",
    "                   patience=0,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# fit\n",
    "model.fit([X_train_stat_, X_train_sn_, X_train_img_], y_train_stat_, \n",
    "          validation_data=([X_val_stat_, X_val_sn_, X_val_img_], y_val_stat_), \n",
    "          epochs=500, \n",
    "          batch_size=1024,\n",
    "          verbose=1, \n",
    "          callbacks=[es])\n",
    "\n",
    "# store the model\n",
    "model.save_weights(\"./model/img_stat_sn_clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test with mydata\n",
    "X_mydata_screennames_encoded_padded = get_ml_screennames(\"data/mydata_screennames.pkl\")\n",
    "X_mydata_stat, y_mydata_stat, mydata = get_ml_stat_data(\"data/mydata.pkl\")\n",
    "X_mydata_img = np.load(\"data/X_np_mydata_image_features.npy\")\n",
    "\n",
    "print(\"Loaing data finished...\")\n",
    "\n",
    "model = img_sn_stat_classifier()\n",
    "model.load_weights(\"model/img_stat_sn_01/img_stat_sn_clf\")\n",
    "\n",
    "pred = model.predict([X_mydata_stat, X_mydata_screennames_encoded_padded, X_mydata_img])\n",
    "pred = np.array(pred>=.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_mydata_stat, \n",
    "                            pred,\n",
    "                            labels = [1, 0],\n",
    "                            target_names=[\"ind\",\"org\"], \n",
    "                            digits=2\n",
    "                           ))\n",
    "\n",
    "with open(\"output/mydata_img_stat_sn_classifier.tsv\", \"w\") as f:\n",
    "    for idx, uid in enumerate(mydata.keys()):\n",
    "        f.write(\"{}\\t{}\\n\".format(uid, pred[idx][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test with humanizer data\n",
    "X_humanizer_screennames_encoded_padded = get_ml_screennames(\"data/humanizer_screennames.pkl\")\n",
    "X_humanizer_stat = np.load(\"data/X_np_humanizer_stat_features.npy\")\n",
    "y_humanizer_stat = np.load(\"data/y_np_humanizer.npy\")\n",
    "X_humanizer_img = np.load(\"data/X_np_humanizer_image_features.npy\")\n",
    "\n",
    "print(\"Loaing data finished...\")\n",
    "\n",
    "model = img_sn_stat_classifier()\n",
    "model.load_weights(\"model/img_stat_sn_01/img_stat_sn_clf\")\n",
    "\n",
    "pred = model.predict([X_humanizer_stat, X_humanizer_screennames_encoded_padded, X_humanizer_img])\n",
    "pred = np.array(pred>=.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_humanizer_stat, \n",
    "                            pred,\n",
    "                            labels = [1, 0],\n",
    "                            target_names=[\"ind\",\"org\"], \n",
    "                            digits=2\n",
    "                           ))\n",
    "\n",
    "with open(\"output/humanizer_img_stat_sn_classifier.tsv\", \"w\") as f:\n",
    "    for idx, uid in enumerate(data.keys()):\n",
    "        f.write(\"{}\\t{}\\n\".format(uid, pred[idx][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inlined test for mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = \"output/mydata_RF_stat_classifier.tsv\"\n",
    "\n",
    "with open(\"data/mydata.pkl\", \"rb\") as f:\n",
    "    mydata = pickle.load(f)\n",
    "\n",
    "# mydata inlined evaluation\n",
    "# get humanizer output\n",
    "houtput = pd.read_csv(\"output/mydata_humanizer.tsv\", \n",
    "                      delimiter=\"\\t\",\n",
    "                      header=None,\n",
    "                      names=[\"user_id\", \"label\"])\n",
    "mydata_uids = houtput[\"user_id\"].values\n",
    "\n",
    "sn_classifier_output = pd.read_csv(pred_file, \n",
    "                      delimiter=\"\\t\",\n",
    "                      header=None,\n",
    "                      names=[\"user_id\", \"label\"])\n",
    "sn_classifier_output = sn_classifier_output[sn_classifier_output[\"user_id\"].isin(mydata_uids)]\n",
    "\n",
    "sn_classifier_output[\"ground_truth\"] = \\\n",
    "    [int(mydata[x][\"label\"]) for x in sn_classifier_output[\"user_id\"].values]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(sn_classifier_output[\"ground_truth\"].values, \n",
    "                            sn_classifier_output[\"label\"].values,\n",
    "                            labels = [1, 0],\n",
    "                            target_names=[\"ind\",\"org\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7tf2.3.0",
   "language": "python",
   "name": "py3.7tf2.3.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
